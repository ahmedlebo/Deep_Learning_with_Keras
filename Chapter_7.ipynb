{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8ee515e-6f9f-4b30-bce2-5a0400eca477",
   "metadata": {},
   "source": [
    "## The Sequential Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143fd62e-fd5c-493f-9c7a-bd56d42a443b",
   "metadata": {},
   "source": [
    "###### The simplest way to build a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31a2d7-4dbe-452c-bd7d-c4fbc96a3595",
   "metadata": {},
   "source": [
    "###### Method 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "193792d9-0ec1-4116-ac34-3fd07e93cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 20:50:20.812922: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2031e551-8d8c-4f16-819e-9e4cc4cbeb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.Sequential([\n",
    "    layers.Dense(64,activation=\"relu\"),\n",
    "    layers.Dense(10,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa9b9c-878e-4e37-aee3-8c2d58247f6f",
   "metadata": {},
   "source": [
    "###### Method 2: build the same model incrementally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d6b780-d872-40f4-bf71-faf788740c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = keras.Sequential()\n",
    "model_2.add(layers.Dense(64,activation=\"relu\"))\n",
    "model_2.add(layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2660df-766e-4aa5-8500-86b5244d809c",
   "metadata": {},
   "source": [
    "the preceding Sequential model does not have any weights until you **actually call it on some data**, or **call its build() method** with an input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674cf3f5-7ee8-4bde-8db7-b61b88428fb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model 'sequential_1' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[0;32m/anaconda3/envs/Deepl/lib/python3.11/site-packages/keras/engine/training.py:3177\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3167\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   3170\u001b[0m \n\u001b[1;32m   3171\u001b[0m \u001b[38;5;124;03m    Note: This will not track the weights of nested `tf.Modules` that are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;124;03m      A list of variables.\u001b[39;00m\n\u001b[1;32m   3176\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dedup_weights(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_undeduplicated_weights\u001b[49m)\n",
      "File \u001b[0;32m/anaconda3/envs/Deepl/lib/python3.11/site-packages/keras/engine/training.py:3182\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_undeduplicated_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3182\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3183\u001b[0m     weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3184\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_tracked_trackables:\n",
      "File \u001b[0;32m/anaconda3/envs/Deepl/lib/python3.11/site-packages/keras/engine/sequential.py:517\u001b[0m, in \u001b[0;36mSequential._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# When the graph has not been initialized, use the Model's\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# implementation to to check if the weights has been created.\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda3/envs/Deepl/lib/python3.11/site-packages/keras/engine/training.py:3540\u001b[0m, in \u001b[0;36mModel._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   3531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3532\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m   3533\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m!=\u001b[39m Model\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[38;5;66;03m# Also make sure to exclude Model class itself which has build()\u001b[39;00m\n\u001b[1;32m   3539\u001b[0m     \u001b[38;5;66;03m# defined.\u001b[39;00m\n\u001b[0;32m-> 3540\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3541\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights for model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m have not yet been \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are created when the model is first called on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs or `build()` is called with an `input_shape`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3545\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model 'sequential_1' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model_2.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a189d53-740a-4193-b4f2-3cc8b3ce3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.build(input_shape=(None,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1097290e-8ca5-40b7-801e-7307382526dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.09300102,  0.27010828,  0.27778238, -0.2963469 , -0.27306196,\n",
       "         -0.0090878 , -0.06362864,  0.02648059,  0.2671584 , -0.1798197 ,\n",
       "         -0.21517628, -0.2582366 , -0.2922574 ,  0.00243115, -0.2293401 ,\n",
       "          0.10958794,  0.09801966,  0.08653352, -0.13266955, -0.15765998,\n",
       "          0.27369344, -0.09521294,  0.11192828,  0.25934845,  0.08088559,\n",
       "          0.29115617, -0.14652151, -0.25919217, -0.16750364,  0.24034643,\n",
       "          0.1042448 , -0.15881959,  0.03722915,  0.13511369,  0.2987792 ,\n",
       "          0.21658409,  0.0596219 , -0.15353246,  0.24998498,  0.06685546,\n",
       "         -0.26027477, -0.13758902, -0.00350702, -0.13071206, -0.00419572,\n",
       "         -0.11774673, -0.26770967, -0.07712208,  0.06836867, -0.12462176,\n",
       "          0.12354857, -0.14861248,  0.09750319,  0.03841382, -0.17177999,\n",
       "         -0.24721584,  0.23273402, -0.20772448, -0.13634886,  0.05762404,\n",
       "         -0.26429498, -0.2865593 ,  0.18683302,  0.17794684],\n",
       "        [ 0.01071432, -0.09228697,  0.10263777, -0.18741457,  0.00897008,\n",
       "          0.25843042, -0.15612409,  0.13225225,  0.02326339,  0.28525585,\n",
       "          0.24166244, -0.01870403, -0.22385243, -0.1604187 ,  0.21707761,\n",
       "         -0.10705796, -0.1457043 , -0.2647225 , -0.21796569,  0.29707557,\n",
       "          0.20552039,  0.28543574, -0.18788397, -0.06173001, -0.29470134,\n",
       "          0.10616356,  0.28172153,  0.18426844, -0.07567678,  0.24905884,\n",
       "          0.01721221, -0.00486183, -0.24578433, -0.27133077,  0.23628485,\n",
       "          0.01443201, -0.18128076,  0.02111307, -0.10386744,  0.0784916 ,\n",
       "         -0.06324051,  0.0166029 , -0.15598495,  0.01116824, -0.20304908,\n",
       "          0.22016025, -0.23216839,  0.19692811, -0.29132047, -0.20627135,\n",
       "          0.22253835, -0.13203512, -0.05535433,  0.07894808,  0.06062976,\n",
       "         -0.23674011, -0.25135377,  0.06923112,  0.00930727, -0.219812  ,\n",
       "          0.01409575, -0.25161847, -0.01092601,  0.00587133],\n",
       "        [-0.00853929, -0.22903952, -0.03908312, -0.2949689 ,  0.27012575,\n",
       "          0.15686467,  0.00507152, -0.06725736, -0.08337632, -0.14118443,\n",
       "          0.25249177,  0.24011916, -0.25742638,  0.26834553,  0.22192353,\n",
       "         -0.2722764 , -0.14717662,  0.29001445, -0.09326328, -0.01730403,\n",
       "          0.10715291,  0.1362429 , -0.22507524, -0.2541029 , -0.10938324,\n",
       "         -0.2572555 ,  0.06837267, -0.19913203,  0.12928605, -0.20799759,\n",
       "          0.16478622,  0.13844639,  0.1589433 , -0.170584  ,  0.04166475,\n",
       "          0.10225135, -0.10525429,  0.15196675,  0.03355584, -0.05749397,\n",
       "         -0.0998396 ,  0.07575983, -0.17883503, -0.25393835, -0.13534307,\n",
       "         -0.14750318, -0.16853268,  0.0621812 , -0.04144558, -0.14120926,\n",
       "          0.11971849, -0.0274263 ,  0.2583719 ,  0.00868654, -0.0151183 ,\n",
       "         -0.18510592,  0.15099463,  0.0638456 ,  0.2894777 ,  0.21479559,\n",
       "          0.10674095, -0.27630097,  0.07374135, -0.16841218]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 0.20509586, -0.16430628,  0.04970729,  0.0732244 ,  0.00155121,\n",
       "         -0.20244202,  0.05218822, -0.21478853,  0.21506518,  0.02504116],\n",
       "        [-0.10606337,  0.15544349,  0.21661451,  0.06134138, -0.05665125,\n",
       "         -0.07494885,  0.04000613,  0.04310298,  0.27978382,  0.09298921],\n",
       "        [ 0.1681264 ,  0.2765232 , -0.14308137, -0.11854573,  0.24786624,\n",
       "          0.051498  ,  0.07525489, -0.02031267, -0.2351257 ,  0.06413454],\n",
       "        [ 0.20788604,  0.07605559,  0.13450536,  0.09486079, -0.25759387,\n",
       "         -0.19787987, -0.14353941,  0.17772672,  0.17104802, -0.26669663],\n",
       "        [-0.16833875, -0.21613353,  0.2159963 , -0.09596051, -0.03892651,\n",
       "          0.17857915,  0.10832164,  0.12404174,  0.01683262, -0.27377042],\n",
       "        [ 0.12708068,  0.16283092, -0.2834057 , -0.0666268 , -0.24861282,\n",
       "          0.21792379, -0.07392067,  0.04292917, -0.20722845, -0.03595085],\n",
       "        [-0.15325122,  0.13028958, -0.10653567,  0.25285926,  0.23827466,\n",
       "         -0.02004838,  0.00607282,  0.22132108,  0.10493207, -0.09784566],\n",
       "        [-0.26345792, -0.25989097,  0.20605934,  0.13103479, -0.15219413,\n",
       "         -0.28331602,  0.00084731, -0.15424193, -0.05928488,  0.18757892],\n",
       "        [-0.13717048, -0.14506075, -0.23730223,  0.2810991 , -0.2468769 ,\n",
       "          0.1430606 , -0.19062972, -0.08064529,  0.04285035, -0.13411227],\n",
       "        [-0.00838789,  0.1565763 ,  0.21309   , -0.00771567, -0.23709747,\n",
       "         -0.02844757, -0.20624605,  0.01132268,  0.25123546,  0.26872936],\n",
       "        [ 0.08280301, -0.17893603,  0.04115367, -0.20201519,  0.19240537,\n",
       "          0.26702073, -0.03570075,  0.10853112,  0.2560856 , -0.04162239],\n",
       "        [ 0.13502938, -0.23644358,  0.04527521, -0.07903971,  0.13285401,\n",
       "          0.24154004, -0.22543481, -0.03792962, -0.13148165,  0.24103424],\n",
       "        [-0.0398798 , -0.15101747, -0.21333447,  0.0924772 ,  0.22147986,\n",
       "          0.22769687, -0.13900816, -0.15039459, -0.01008382,  0.10426384],\n",
       "        [-0.14768392,  0.06773904,  0.03827083, -0.21769235,  0.09928015,\n",
       "          0.22345635, -0.07568355, -0.01397699, -0.00132051,  0.03857979],\n",
       "        [-0.1027649 ,  0.11972454, -0.24970727, -0.22875404, -0.08678612,\n",
       "          0.28311387,  0.25897184,  0.11507428, -0.23535463, -0.05807218],\n",
       "        [-0.04685289,  0.07359624, -0.12036569,  0.13789621, -0.10466655,\n",
       "          0.22339001, -0.15629978, -0.16503812,  0.14252311, -0.26194474],\n",
       "        [ 0.07754168,  0.04501793,  0.02783093,  0.13481697, -0.00752211,\n",
       "          0.1430411 , -0.13682832, -0.00562793, -0.26849326,  0.06980428],\n",
       "        [ 0.22138128, -0.11831667,  0.10353076, -0.21340698,  0.04781747,\n",
       "         -0.28259876,  0.22746852, -0.05618085, -0.05207634,  0.20640734],\n",
       "        [ 0.1915924 ,  0.14625919, -0.13163467,  0.11485642,  0.19786915,\n",
       "         -0.04640163, -0.05848555,  0.22203436, -0.18244956, -0.2693298 ],\n",
       "        [ 0.23487076,  0.22174618,  0.11621258,  0.15378225, -0.16632937,\n",
       "          0.13681847, -0.11047655, -0.01706019, -0.00421014, -0.07600303],\n",
       "        [ 0.03522465,  0.00344726,  0.02151105,  0.00963387, -0.275844  ,\n",
       "         -0.00697309,  0.08406845, -0.15836443,  0.04137397,  0.0429835 ],\n",
       "        [ 0.28447685,  0.06122372, -0.28022924,  0.02623037,  0.02941069,\n",
       "         -0.19454041, -0.19231093, -0.00693983,  0.14562815,  0.27069315],\n",
       "        [-0.1481706 , -0.04496226,  0.20902291,  0.23394433,  0.12817246,\n",
       "         -0.27154493,  0.1567693 ,  0.02970248, -0.16408855, -0.14775729],\n",
       "        [-0.2683651 , -0.20719784, -0.11632833,  0.28125057, -0.03380075,\n",
       "          0.2052165 ,  0.25378582,  0.16131285, -0.18167563, -0.00456235],\n",
       "        [-0.22145414,  0.26378605, -0.07212718, -0.26886806,  0.09648952,\n",
       "          0.2004092 ,  0.19833574, -0.01403463, -0.03945577,  0.23284647],\n",
       "        [-0.13489537,  0.1445173 , -0.06866674,  0.19900301,  0.1478087 ,\n",
       "         -0.07845281,  0.19357806,  0.04855242, -0.05688119,  0.10927343],\n",
       "        [ 0.15277043,  0.1967904 ,  0.1042681 ,  0.2607843 , -0.104736  ,\n",
       "          0.17928132,  0.27750388, -0.16975445, -0.03964755,  0.19804835],\n",
       "        [ 0.09333757, -0.26385656,  0.07947421,  0.25351235,  0.2247856 ,\n",
       "         -0.06728771,  0.09337544,  0.07455212, -0.2536701 ,  0.03135157],\n",
       "        [ 0.1732324 , -0.16764078, -0.1464099 ,  0.09991947, -0.09770635,\n",
       "          0.04840741,  0.01160258, -0.2770401 ,  0.10224819, -0.11396769],\n",
       "        [-0.09256119, -0.2645694 , -0.10559425,  0.04642805, -0.22951217,\n",
       "         -0.1605098 , -0.04952732,  0.20794979,  0.10931051,  0.18811437],\n",
       "        [-0.0534564 ,  0.14679003,  0.19481134, -0.26087958, -0.0547194 ,\n",
       "          0.26770195, -0.09685598, -0.23714426, -0.06365557, -0.27859542],\n",
       "        [ 0.09071282, -0.24823461, -0.06653352,  0.225194  , -0.24307334,\n",
       "         -0.17478496, -0.09982769, -0.1184151 ,  0.05777326, -0.28121328],\n",
       "        [-0.22405192, -0.18861762, -0.06665573, -0.10743302,  0.25559393,\n",
       "          0.276683  ,  0.12292302, -0.23043993, -0.19279423, -0.16717514],\n",
       "        [-0.09294951, -0.20578928,  0.14929959,  0.08614138, -0.1711055 ,\n",
       "         -0.13333617,  0.23387447, -0.14787726,  0.03535908, -0.10016985],\n",
       "        [ 0.2600319 , -0.21577623,  0.04202333,  0.0214245 ,  0.24075058,\n",
       "         -0.00491497, -0.20183623, -0.13771833, -0.00716683, -0.16735029],\n",
       "        [-0.21515417, -0.08358957, -0.0859845 , -0.12019448,  0.05472219,\n",
       "          0.00866821,  0.00825694, -0.07016423, -0.19929582,  0.01097292],\n",
       "        [-0.0562655 , -0.07935804,  0.10444012,  0.15055534, -0.19106314,\n",
       "          0.07601622,  0.06316909, -0.06749232,  0.08853734,  0.13591003],\n",
       "        [-0.10296138,  0.24747726, -0.2568507 ,  0.25158003, -0.08249711,\n",
       "          0.09128344,  0.01618904,  0.10717714,  0.09789774,  0.05485511],\n",
       "        [ 0.1542086 ,  0.21198857, -0.08452393, -0.12309626,  0.10345697,\n",
       "         -0.1528401 , -0.1020017 ,  0.16771424,  0.2435213 , -0.1257626 ],\n",
       "        [-0.07106125,  0.13982928, -0.14888562,  0.23473069, -0.02923006,\n",
       "          0.0411534 ,  0.15824568,  0.25371584, -0.14670563, -0.00745013],\n",
       "        [ 0.12771544, -0.00964981, -0.01143768, -0.13720483,  0.08966884,\n",
       "         -0.09030271,  0.1218541 , -0.19178316,  0.04704827,  0.21891972],\n",
       "        [-0.11482133, -0.0388739 , -0.01838523,  0.01806867, -0.12440611,\n",
       "         -0.12054831, -0.04624318,  0.00577736,  0.18280801, -0.16350871],\n",
       "        [ 0.04688841,  0.0284633 , -0.02647001,  0.01214129,  0.0015434 ,\n",
       "          0.10264915,  0.06509373, -0.06886871,  0.27078113, -0.00580806],\n",
       "        [ 0.15995899, -0.14780265,  0.23460332,  0.15378463, -0.04050452,\n",
       "          0.1912606 , -0.02254969,  0.14875615,  0.28224656,  0.14330363],\n",
       "        [-0.24999017,  0.17821261, -0.17478773, -0.10179585,  0.14448857,\n",
       "          0.1263806 , -0.02189845,  0.09405828,  0.18052885, -0.27872503],\n",
       "        [-0.16889775,  0.18897846,  0.0599736 ,  0.25604245,  0.10256836,\n",
       "         -0.12617809,  0.2623845 , -0.18321663,  0.04372159,  0.0910632 ],\n",
       "        [ 0.27371255,  0.10565522,  0.14984164,  0.1834214 ,  0.18275288,\n",
       "         -0.2083062 ,  0.2171556 , -0.20981783,  0.26978782, -0.13108544],\n",
       "        [-0.16724078,  0.11830851,  0.24363175,  0.04144743,  0.20791033,\n",
       "         -0.00399223, -0.00737655,  0.19197094, -0.12996072,  0.2683272 ],\n",
       "        [ 0.13748935,  0.17017704, -0.15493792,  0.2121169 , -0.00189769,\n",
       "          0.03377759,  0.2324892 ,  0.23874328,  0.23369911,  0.25338206],\n",
       "        [-0.00029132, -0.15016513,  0.01898009,  0.26968083, -0.22987388,\n",
       "         -0.16108948, -0.28029597,  0.27385738,  0.08002037,  0.16934568],\n",
       "        [-0.2774584 ,  0.14564222,  0.07075685, -0.2769327 , -0.28467733,\n",
       "          0.2640405 ,  0.00312337,  0.23971412,  0.22229645,  0.18076375],\n",
       "        [-0.17032702,  0.16318324, -0.14143208,  0.01192254,  0.06361836,\n",
       "          0.07387742,  0.19683477,  0.2559171 ,  0.12360597, -0.19421718],\n",
       "        [-0.12432341,  0.19022232, -0.03068173,  0.27314475,  0.08874527,\n",
       "         -0.10977411,  0.1288554 ,  0.24201068,  0.05209041,  0.19621563],\n",
       "        [-0.07762721,  0.18168446, -0.24335726,  0.14444852, -0.00433609,\n",
       "          0.11770877, -0.14717814, -0.19486287,  0.18821159, -0.09653927],\n",
       "        [ 0.20131993, -0.25592935,  0.001477  ,  0.2577676 , -0.0656469 ,\n",
       "         -0.2587301 ,  0.12131995,  0.11159658,  0.19858652,  0.21415219],\n",
       "        [ 0.058359  , -0.24783461, -0.02290061, -0.12352769,  0.06787392,\n",
       "          0.14445478, -0.2191565 , -0.11191723, -0.22073588,  0.06966987],\n",
       "        [ 0.08508292, -0.10889685,  0.01604056,  0.08381781, -0.20787938,\n",
       "         -0.27632514,  0.08859301, -0.02143103, -0.0640509 , -0.09446594],\n",
       "        [ 0.2685497 , -0.15424587, -0.17305976, -0.14984   ,  0.27463052,\n",
       "          0.25641468,  0.2723404 , -0.00911343,  0.19182056,  0.02641734],\n",
       "        [ 0.08990008,  0.04503265,  0.2757875 , -0.2532189 , -0.02958801,\n",
       "          0.03143692, -0.16229758, -0.07572095,  0.10216701,  0.18996787],\n",
       "        [ 0.21901426, -0.08210701,  0.11427808,  0.20853302,  0.20125538,\n",
       "          0.00986463, -0.00444952, -0.05048387,  0.06223357, -0.11130834],\n",
       "        [-0.13675438,  0.10666806,  0.10957676, -0.02435404,  0.0604502 ,\n",
       "          0.10474828,  0.14593333,  0.03887838,  0.01013795,  0.20309108],\n",
       "        [ 0.2759548 ,  0.27203342,  0.1495753 , -0.20362797,  0.26891407,\n",
       "         -0.00836733,  0.1386056 , -0.26660478,  0.09521645,  0.06905955],\n",
       "        [-0.26008642,  0.09681958,  0.24656948,  0.162429  , -0.10060833,\n",
       "          0.0121901 ,  0.16224971,  0.1806499 , -0.03470993, -0.12256944],\n",
       "        [-0.0285477 , -0.2773627 , -0.1609734 , -0.21362159, -0.00065479,\n",
       "          0.15390655,  0.24571833, -0.02352649,  0.18161759, -0.2597048 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ae5623-9541-40f9-8280-fc2c700d0aec",
   "metadata": {},
   "source": [
    "Builds the model—now the model will expect samples to be:\n",
    "- of shape (3,).\n",
    "- The None in the input shape signals that **the batch size could be anything**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf7023c-4155-4261-a45f-e73255560151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                256       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5515124-c6d0-4afc-b7b6-f611c8988d8c",
   "metadata": {},
   "source": [
    "### Naming models and layers with the name argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a4d7ea-7238-462c-a7a7-0b757cee7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_named = keras.Sequential(name = \"my_example_model\")\n",
    "model_named.add(layers.Dense(64, activation = \"relu\",name = \"my_first_layer\"))\n",
    "model_named.add(layers.Dense(10, activation = \"softmax\",name = \"my_second_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4e7239-cba5-4521-a355-c033a0fac122",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_named.build(input_shape=(None,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f104d28-20ee-465d-b2b9-38f334f82926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_second_layer (Dense)     (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_named.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61db4b2-10ab-4c3d-beb0-1ea4b4bbd81a",
   "metadata": {},
   "source": [
    "There’s actually a way to have your Sequential built on the fly: just declare the shape of the model’s inputs in advance. You can do this via the Input class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717ecedb-356f-4941-9c5d-45c370b1fd4b",
   "metadata": {},
   "source": [
    "### Specifying the input shape of your model in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2f699ad-2a9e-4267-9a48-3175da5058e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_specified = keras.Sequential(name=\"model_with_specified_input_shape\")\n",
    "model_input_specified.add(keras.Input(shape=(3,)))\n",
    "model_input_specified.add(layers.Dense(64, activation = \"relu\",name = \"my_first_layer\"))\n",
    "model_input_specified.add(layers.Dense(10, activation = \"softmax\",name = \"my_second_layer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48179460-2152-4e8c-9f7e-7c66c7ed739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_with_specified_input_shape\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_second_layer (Dense)     (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input_specified.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74ac7ae-0b52-4dc8-ac44-a4b88abd6099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cce2fdf5-f460-4190-a611-1445966cba22",
   "metadata": {},
   "source": [
    "## The Functional API:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89b0759-0842-4cfe-84fd-05b21efa71a7",
   "metadata": {},
   "source": [
    "##### A simple Functional model with two Dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f71c32-d5d0-4957-9b06-e2c96ec2aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step: declaring an Input (note that you can also give names to these input objects, like everything else)\n",
    "inputs = keras.Input(shape=(3,),name=\"my_input\")\n",
    "#Next, we created a layer and called it on the inputs tensor(actually a symbolic tensor):because It doesn’t contain any actual data,\n",
    "# but it encodes the specifications of the actual tensors of data that the model will see when you use it. \n",
    "# It stands for future tensors of data.\n",
    "features = layers.Dense(64,activation=\"relu\")(inputs)\n",
    "# Last, After obtaining the final outputs, we instantiated the model by specifying its inputs and outputs in the Model constructor\n",
    "outputs = layers.Dense(10,activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "778eb752-787a-46bd-b6b3-f428ad71dc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb59f70f-51a3-4c1a-b0b5-7a043a8bf335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e85ba-0602-4b2a-81ca-f8c29243f458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be6f5c6c-30b9-4a86-9974-1ef6e293ae06",
   "metadata": {},
   "source": [
    "##### MULTI-INPUT, MULTI-OUTPUT MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5cb3b2-da96-4501-9e2f-e9fd2bde1b5e",
   "metadata": {},
   "source": [
    "###### Example : A system to rank customer support tickets by priority and route them to the appropriate department\n",
    "###### Inputs are :\n",
    "- The title of the ticket (text input)\n",
    "- The text body of the ticket (text input)\n",
    "- Any tags added by the user (categorical input, assumed here to be one-hot encoded)\n",
    "\n",
    "###### Outputs are :\n",
    "- The priority score of the ticket, a scalar between 0 and 1 (sigmoid output)\n",
    "- The department that should handle the ticket (a softmax over the set of departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f20feb-37ce-49f9-974d-da9fcf47b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000 # Represents the size of the input layer for the title with a shape of (vocabulary_size,).\n",
    "num_tags = 100 # Input layer representing tags associated with the text with a shape of (num_tags,)\n",
    "num_departments = 4\n",
    "\n",
    "## DEFINE Inputs to the model\n",
    "title = keras.Input(shape = (vocabulary_size,),name = \"title\")\n",
    "text_body = keras.Input(shape = (vocabulary_size,),name = \"text_body\")\n",
    "tags_input = keras.Input(shape = (num_tags,),name = \"tags_input\")\n",
    "\n",
    "## Concatenate to create features layer\n",
    "features = layers.Concatenate()([title,text_body,tags_input])\n",
    "## Apply an intermediate layer to recombine input features into richer representations.\n",
    "features = layers.Dense(64, activation =\"relu\")(features)\n",
    "\n",
    "## Define priority score output\n",
    "score_output = layers.Dense(1,activation = \"sigmoid\", name = \"priority\")(features)\n",
    "## Department output \n",
    "department_output = layers.Dense(num_departments,activation = \"softmax\",name=\"Department_specified\")(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dfb020c-979c-42da-8e41-dc37153ad55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_io_model = keras.Model(inputs=[title, text_body, tags_input],\n",
    "                       outputs=[score_output, department_output])\n",
    "# The Functional API is a simple, LEGO-like, yet very flexible way to define arbitrary graphs of layers like these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0af6a39a-92f4-4f40-809d-bb7e32a400d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Example text input\n",
    "ticket_text = \"Hello, I'm experiencing issues with my internet connection. It keeps disconnecting frequently.\"\n",
    "# Example department and priority score\n",
    "department = \"Technical Support\"\n",
    "priority = 0.9\n",
    "\n",
    "# Tokenize the text input\n",
    "tokenizer = keras.preprocessing.text.Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts([ticket_text])\n",
    "text_encoded = tokenizer.texts_to_matrix([ticket_text], mode='binary')\n",
    "\n",
    "# Create one-hot encoded department vector\n",
    "department_encoded = np.zeros(num_departments)\n",
    "department_index = {\"Technical Support\": 0, \"Billing\": 1, \"Product Inquiry\": 2, \"General Inquiry\": 3}\n",
    "department_encoded[department_index[department]] = 1\n",
    "\n",
    "# Create numpy array for the priority score\n",
    "priority_score = np.array([[priority]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ceb352-8176-4780-a561-4ead4b39ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_io_model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"Department_specified\":\"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"Department_specified\":[\"accuracy\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cfe5938-2965-464b-a379-707149a3dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_data = text_encoded\n",
    "text_body_data = text_encoded\n",
    "tags_data = np.zeros(num_tags)\n",
    "tags_data = tags_data.reshape(1,-1)\n",
    "department_data = department_encoded.reshape(1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b60397-fedc-4909-875d-b609047c3b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 1.5000 - priority_loss: 0.1609 - Department_specified_loss: 1.3391 - priority_mean_absolute_error: 0.4011 - Department_specified_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 1.2058 - priority_loss: 0.1370 - Department_specified_loss: 1.0688 - priority_mean_absolute_error: 0.3701 - Department_specified_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 127ms/step\n"
     ]
    }
   ],
   "source": [
    "## Train_model for low number_of_epochs\n",
    "multi_io_model.fit({\"title\": title_data, \"text_body\": text_body_data,\"tags_input\": tags_data},\n",
    "          {\"priority\": priority_score, \"Department_specified\": department_data},epochs=1)\n",
    "multi_io_model.evaluate({\"title\": title_data, \"text_body\": text_body_data,\"tags_input\": tags_data},\n",
    "{\"priority\": priority_score, \"Department_specified\": department_data}) \n",
    "priority_preds, department_preds = multi_io_model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags_input\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b4b802-39d6-443a-a607-62f50c8d4571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5299287]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa494af-ce48-4b0f-b886-bc52db37c465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.34342095, 0.23479526, 0.24192351, 0.17986034]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95478030-ad24-44bf-aa81-cb5e502ee11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac05b91-5f54-477b-8c5a-dd4f47aa4edb",
   "metadata": {},
   "source": [
    "We can see that the model didn't train long enough to predict the only input right so lets's increase number of epochs for training to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4466b1c9-22d3-49ab-b728-38188caa5efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2058 - priority_loss: 0.1370 - Department_specified_loss: 1.0688 - priority_mean_absolute_error: 0.3701 - Department_specified_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.0536 - priority_loss: 0.1242 - Department_specified_loss: 0.9294 - priority_mean_absolute_error: 0.3524 - Department_specified_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.9342 - priority_loss: 0.1133 - Department_specified_loss: 0.8210 - priority_mean_absolute_error: 0.3365 - Department_specified_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8340 - priority_loss: 0.1035 - Department_specified_loss: 0.7304 - priority_mean_absolute_error: 0.3218 - Department_specified_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.7479 - priority_loss: 0.0948 - Department_specified_loss: 0.6531 - priority_mean_absolute_error: 0.3079 - Department_specified_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6730 - priority_loss: 0.0869 - Department_specified_loss: 0.5861 - priority_mean_absolute_error: 0.2948 - Department_specified_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6073 - priority_loss: 0.0796 - Department_specified_loss: 0.5276 - priority_mean_absolute_error: 0.2822 - Department_specified_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5493 - priority_loss: 0.0730 - Department_specified_loss: 0.4762 - priority_mean_absolute_error: 0.2702 - Department_specified_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4978 - priority_loss: 0.0669 - Department_specified_loss: 0.4309 - priority_mean_absolute_error: 0.2587 - Department_specified_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4520 - priority_loss: 0.0613 - Department_specified_loss: 0.3907 - priority_mean_absolute_error: 0.2476 - Department_specified_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4111 - priority_loss: 0.0562 - Department_specified_loss: 0.3550 - priority_mean_absolute_error: 0.2370 - Department_specified_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3745 - priority_loss: 0.0514 - Department_specified_loss: 0.3231 - priority_mean_absolute_error: 0.2267 - Department_specified_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3417 - priority_loss: 0.0470 - Department_specified_loss: 0.2947 - priority_mean_absolute_error: 0.2169 - Department_specified_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3122 - priority_loss: 0.0430 - Department_specified_loss: 0.2692 - priority_mean_absolute_error: 0.2074 - Department_specified_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.2857 - priority_loss: 0.0393 - Department_specified_loss: 0.2464 - priority_mean_absolute_error: 0.1982 - Department_specified_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2617 - priority_loss: 0.0359 - Department_specified_loss: 0.2258 - priority_mean_absolute_error: 0.1894 - Department_specified_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2400 - priority_loss: 0.0327 - Department_specified_loss: 0.2073 - priority_mean_absolute_error: 0.1809 - Department_specified_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2204 - priority_loss: 0.0298 - Department_specified_loss: 0.1905 - priority_mean_absolute_error: 0.1728 - Department_specified_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2026 - priority_loss: 0.0272 - Department_specified_loss: 0.1754 - priority_mean_absolute_error: 0.1649 - Department_specified_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1864 - priority_loss: 0.0247 - Department_specified_loss: 0.1617 - priority_mean_absolute_error: 0.1573 - Department_specified_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1717 - priority_loss: 0.0225 - Department_specified_loss: 0.1492 - priority_mean_absolute_error: 0.1500 - Department_specified_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.1583 - priority_loss: 0.0204 - Department_specified_loss: 0.1379 - priority_mean_absolute_error: 0.1429 - Department_specified_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1461 - priority_loss: 0.0185 - Department_specified_loss: 0.1276 - priority_mean_absolute_error: 0.1361 - Department_specified_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1349 - priority_loss: 0.0168 - Department_specified_loss: 0.1181 - priority_mean_absolute_error: 0.1296 - Department_specified_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1247 - priority_loss: 0.0152 - Department_specified_loss: 0.1095 - priority_mean_absolute_error: 0.1233 - Department_specified_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1154 - priority_loss: 0.0137 - Department_specified_loss: 0.1016 - priority_mean_absolute_error: 0.1172 - Department_specified_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.1068 - priority_loss: 0.0124 - Department_specified_loss: 0.0944 - priority_mean_absolute_error: 0.1114 - Department_specified_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0990 - priority_loss: 0.0112 - Department_specified_loss: 0.0878 - priority_mean_absolute_error: 0.1058 - Department_specified_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0917 - priority_loss: 0.0101 - Department_specified_loss: 0.0817 - priority_mean_absolute_error: 0.1004 - Department_specified_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0851 - priority_loss: 0.0091 - Department_specified_loss: 0.0760 - priority_mean_absolute_error: 0.0952 - Department_specified_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0790 - priority_loss: 0.0081 - Department_specified_loss: 0.0709 - priority_mean_absolute_error: 0.0902 - Department_specified_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0734 - priority_loss: 0.0073 - Department_specified_loss: 0.0661 - priority_mean_absolute_error: 0.0853 - Department_specified_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0682 - priority_loss: 0.0065 - Department_specified_loss: 0.0617 - priority_mean_absolute_error: 0.0807 - Department_specified_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0634 - priority_loss: 0.0058 - Department_specified_loss: 0.0576 - priority_mean_absolute_error: 0.0762 - Department_specified_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0590 - priority_loss: 0.0052 - Department_specified_loss: 0.0538 - priority_mean_absolute_error: 0.0719 - Department_specified_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0549 - priority_loss: 0.0046 - Department_specified_loss: 0.0504 - priority_mean_absolute_error: 0.0678 - Department_specified_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0512 - priority_loss: 0.0041 - Department_specified_loss: 0.0471 - priority_mean_absolute_error: 0.0638 - Department_specified_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0477 - priority_loss: 0.0036 - Department_specified_loss: 0.0441 - priority_mean_absolute_error: 0.0600 - Department_specified_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0445 - priority_loss: 0.0032 - Department_specified_loss: 0.0413 - priority_mean_absolute_error: 0.0563 - Department_specified_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0415 - priority_loss: 0.0028 - Department_specified_loss: 0.0387 - priority_mean_absolute_error: 0.0528 - Department_specified_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0387 - priority_loss: 0.0024 - Department_specified_loss: 0.0363 - priority_mean_absolute_error: 0.0494 - Department_specified_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - priority_loss: 0.0021 - Department_specified_loss: 0.0341 - priority_mean_absolute_error: 0.0462 - Department_specified_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - priority_loss: 0.0019 - Department_specified_loss: 0.0320 - priority_mean_absolute_error: 0.0431 - Department_specified_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0316 - priority_loss: 0.0016 - Department_specified_loss: 0.0300 - priority_mean_absolute_error: 0.0401 - Department_specified_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0296 - priority_loss: 0.0014 - Department_specified_loss: 0.0282 - priority_mean_absolute_error: 0.0372 - Department_specified_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0277 - priority_loss: 0.0012 - Department_specified_loss: 0.0265 - priority_mean_absolute_error: 0.0345 - Department_specified_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0259 - priority_loss: 0.0010 - Department_specified_loss: 0.0249 - priority_mean_absolute_error: 0.0319 - Department_specified_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0243 - priority_loss: 8.6128e-04 - Department_specified_loss: 0.0234 - priority_mean_absolute_error: 0.0293 - Department_specified_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0228 - priority_loss: 7.2626e-04 - Department_specified_loss: 0.0220 - priority_mean_absolute_error: 0.0269 - Department_specified_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0213 - priority_loss: 6.0812e-04 - Department_specified_loss: 0.0207 - priority_mean_absolute_error: 0.0247 - Department_specified_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0200 - priority_loss: 5.0524e-04 - Department_specified_loss: 0.0195 - priority_mean_absolute_error: 0.0225 - Department_specified_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0188 - priority_loss: 4.1613e-04 - Department_specified_loss: 0.0184 - priority_mean_absolute_error: 0.0204 - Department_specified_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0177 - priority_loss: 3.3941e-04 - Department_specified_loss: 0.0173 - priority_mean_absolute_error: 0.0184 - Department_specified_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0166 - priority_loss: 2.7380e-04 - Department_specified_loss: 0.0163 - priority_mean_absolute_error: 0.0165 - Department_specified_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0156 - priority_loss: 2.1811e-04 - Department_specified_loss: 0.0154 - priority_mean_absolute_error: 0.0148 - Department_specified_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0147 - priority_loss: 1.7127e-04 - Department_specified_loss: 0.0145 - priority_mean_absolute_error: 0.0131 - Department_specified_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0138 - priority_loss: 1.3224e-04 - Department_specified_loss: 0.0137 - priority_mean_absolute_error: 0.0115 - Department_specified_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0130 - priority_loss: 1.0011e-04 - Department_specified_loss: 0.0129 - priority_mean_absolute_error: 0.0100 - Department_specified_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0122 - priority_loss: 7.4007e-05 - Department_specified_loss: 0.0122 - priority_mean_absolute_error: 0.0086 - Department_specified_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0115 - priority_loss: 5.3143e-05 - Department_specified_loss: 0.0115 - priority_mean_absolute_error: 0.0073 - Department_specified_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0109 - priority_loss: 3.6794e-05 - Department_specified_loss: 0.0108 - priority_mean_absolute_error: 0.0061 - Department_specified_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0103 - priority_loss: 2.4293e-05 - Department_specified_loss: 0.0102 - priority_mean_absolute_error: 0.0049 - Department_specified_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0097 - priority_loss: 1.5037e-05 - Department_specified_loss: 0.0097 - priority_mean_absolute_error: 0.0039 - Department_specified_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0091 - priority_loss: 8.4734e-06 - Department_specified_loss: 0.0091 - priority_mean_absolute_error: 0.0029 - Department_specified_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0086 - priority_loss: 4.1089e-06 - Department_specified_loss: 0.0086 - priority_mean_absolute_error: 0.0020 - Department_specified_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0082 - priority_loss: 1.4992e-06 - Department_specified_loss: 0.0082 - priority_mean_absolute_error: 0.0012 - Department_specified_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0077 - priority_loss: 2.5140e-07 - Department_specified_loss: 0.0077 - priority_mean_absolute_error: 5.0139e-04 - Department_specified_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0073 - priority_loss: 2.0755e-08 - Department_specified_loss: 0.0073 - priority_mean_absolute_error: 1.4406e-04 - Department_specified_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0069 - priority_loss: 5.0963e-07 - Department_specified_loss: 0.0069 - priority_mean_absolute_error: 7.1388e-04 - Department_specified_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0065 - priority_loss: 1.4653e-06 - Department_specified_loss: 0.0065 - priority_mean_absolute_error: 0.0012 - Department_specified_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - priority_loss: 2.6783e-06 - Department_specified_loss: 0.0062 - priority_mean_absolute_error: 0.0016 - Department_specified_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0058 - priority_loss: 3.9804e-06 - Department_specified_loss: 0.0058 - priority_mean_absolute_error: 0.0020 - Department_specified_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - priority_loss: 5.2406e-06 - Department_specified_loss: 0.0055 - priority_mean_absolute_error: 0.0023 - Department_specified_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0052 - priority_loss: 6.3647e-06 - Department_specified_loss: 0.0052 - priority_mean_absolute_error: 0.0025 - Department_specified_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - priority_loss: 7.2879e-06 - Department_specified_loss: 0.0049 - priority_mean_absolute_error: 0.0027 - Department_specified_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - priority_loss: 7.9757e-06 - Department_specified_loss: 0.0047 - priority_mean_absolute_error: 0.0028 - Department_specified_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0044 - priority_loss: 8.4156e-06 - Department_specified_loss: 0.0044 - priority_mean_absolute_error: 0.0029 - Department_specified_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0042 - priority_loss: 8.6145e-06 - Department_specified_loss: 0.0042 - priority_mean_absolute_error: 0.0029 - Department_specified_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - priority_loss: 8.5932e-06 - Department_specified_loss: 0.0040 - priority_mean_absolute_error: 0.0029 - Department_specified_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - priority_loss: 8.3838e-06 - Department_specified_loss: 0.0038 - priority_mean_absolute_error: 0.0029 - Department_specified_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0036 - priority_loss: 8.0222e-06 - Department_specified_loss: 0.0036 - priority_mean_absolute_error: 0.0028 - Department_specified_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - priority_loss: 7.5476e-06 - Department_specified_loss: 0.0034 - priority_mean_absolute_error: 0.0027 - Department_specified_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - priority_loss: 6.9974e-06 - Department_specified_loss: 0.0032 - priority_mean_absolute_error: 0.0026 - Department_specified_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - priority_loss: 6.4053e-06 - Department_specified_loss: 0.0030 - priority_mean_absolute_error: 0.0025 - Department_specified_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - priority_loss: 5.8003e-06 - Department_specified_loss: 0.0029 - priority_mean_absolute_error: 0.0024 - Department_specified_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0027 - priority_loss: 5.2052e-06 - Department_specified_loss: 0.0027 - priority_mean_absolute_error: 0.0023 - Department_specified_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0026 - priority_loss: 4.6379e-06 - Department_specified_loss: 0.0026 - priority_mean_absolute_error: 0.0022 - Department_specified_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - priority_loss: 4.1091e-06 - Department_specified_loss: 0.0024 - priority_mean_absolute_error: 0.0020 - Department_specified_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0023 - priority_loss: 3.6259e-06 - Department_specified_loss: 0.0023 - priority_mean_absolute_error: 0.0019 - Department_specified_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0022 - priority_loss: 3.1906e-06 - Department_specified_loss: 0.0022 - priority_mean_absolute_error: 0.0018 - Department_specified_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0021 - priority_loss: 2.8031e-06 - Department_specified_loss: 0.0021 - priority_mean_absolute_error: 0.0017 - Department_specified_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0020 - priority_loss: 2.4609e-06 - Department_specified_loss: 0.0020 - priority_mean_absolute_error: 0.0016 - Department_specified_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0019 - priority_loss: 2.1610e-06 - Department_specified_loss: 0.0019 - priority_mean_absolute_error: 0.0015 - Department_specified_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0018 - priority_loss: 1.8984e-06 - Department_specified_loss: 0.0018 - priority_mean_absolute_error: 0.0014 - Department_specified_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0017 - priority_loss: 1.6697e-06 - Department_specified_loss: 0.0017 - priority_mean_absolute_error: 0.0013 - Department_specified_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0016 - priority_loss: 1.4701e-06 - Department_specified_loss: 0.0016 - priority_mean_absolute_error: 0.0012 - Department_specified_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0015 - priority_loss: 1.2959e-06 - Department_specified_loss: 0.0015 - priority_mean_absolute_error: 0.0011 - Department_specified_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0014 - priority_loss: 1.1438e-06 - Department_specified_loss: 0.0014 - priority_mean_absolute_error: 0.0011 - Department_specified_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0013 - priority_loss: 1.0107e-06 - Department_specified_loss: 0.0013 - priority_mean_absolute_error: 0.0010 - Department_specified_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0013 - priority_loss: 8.9399e-07 - Department_specified_loss: 0.0013 - priority_mean_absolute_error: 9.4551e-04 - Department_specified_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - priority_loss: 7.9160e-07 - Department_specified_loss: 0.0012 - priority_mean_absolute_error: 8.8972e-04 - Department_specified_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    }
   ],
   "source": [
    "## Train_model for low number_of_epochs\n",
    "multi_io_model.fit({\"title\": title_data, \"text_body\": text_body_data,\"tags_input\": tags_data},\n",
    "          {\"priority\": priority_score, \"Department_specified\": department_data},epochs=100)\n",
    "multi_io_model.evaluate({\"title\": title_data, \"text_body\": text_body_data,\"tags_input\": tags_data},\n",
    "{\"priority\": priority_score, \"Department_specified\": department_data}) \n",
    "priority_preds, department_preds = multi_io_model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags_input\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f67bdfd-3248-4720-9b47-e6d7de0af558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9008897]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "723cdce3-4194-42ac-b46d-a4b5fcbd93d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.987924e-01, 4.287491e-04, 6.850473e-04, 9.370106e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6d638f-48c3-48db-a3eb-3cb002f7e86f",
   "metadata": {},
   "source": [
    "##### We can see that the model here puts the highest probabilty to the right department and a very close number to the real priority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22e1e11-7979-4e4e-8011-b74173321456",
   "metadata": {},
   "source": [
    "##### THE POWER OF THE FUNCTIONAL API: ACCESS TO LAYER CONNECTIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cc760ef-4221-417f-a910-148785a209b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a Functional model as a graph\n",
    "keras.utils.plot_model(multi_io_model,to_file =\"multi_io_model_functional.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48a2a02c-fa07-4150-8362-4ee9699a74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add to this plot the input and output shapes of each layer in the model, which can be helpful during debugging\n",
    "keras.utils.plot_model(multi_io_model, \"ticket_classifier_with_shape_info.pdf\", show_shapes=True)\n",
    "# The “None” in the tensor shapes represents the batch size: this model allows batches of any size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99dbb709-3f03-4b69-a7c6-ddfd369bce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x14aca4d50>,\n",
       " <keras.engine.input_layer.InputLayer at 0x14b6e0c90>,\n",
       " <keras.engine.input_layer.InputLayer at 0x14ab79b90>,\n",
       " <keras.layers.merging.concatenate.Concatenate at 0x14ab6b350>,\n",
       " <keras.layers.core.dense.Dense at 0x14b7e1550>,\n",
       " <keras.layers.core.dense.Dense at 0x14a1dcb90>,\n",
       " <keras.layers.core.dense.Dense at 0x14b6e7710>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_io_model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53e5a52d-5ba7-4062-9de1-51237f079bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags_input')>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_io_model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b3dab5a-5d55-4a2d-95fa-14718119506a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_io_model.layers[3].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5036f385-3ee4-4b92-abf2-7fead084e85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 64) dtype=float32 (created by layer 'dense_6')>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_io_model.layers[4].output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fae1c9-5815-4cba-a0b8-0bfd53bc2a2b",
   "metadata": {},
   "source": [
    "#### Creating a new model by reusing intermediate layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8fed6d8-d746-4030-9fc3-e31abf87eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers[4] is our intermediate Dense layer\n",
    "features_req = multi_io_model.layers[4].output\n",
    "## Adding difficulty output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features_req)\n",
    "## Creating new model\n",
    "new_model_io = keras.Model(inputs=[title, text_body, tags_input], \n",
    "                           outputs=[score_output, department_output, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83bfbf42-1098-4861-a600-8cf826b16709",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(\n",
    "    new_model_io, \"updated_ticket_classifier.pdf\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd115e-07a6-41b1-946b-73c1c9f5b0e3",
   "metadata": {},
   "source": [
    "## Subclassing the Model class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2460f-50e2-420b-ba71-9b0e48197c93",
   "metadata": {},
   "source": [
    "It is the most advanced one. Subclassing Model is pretty similar:\n",
    "- In the __init__() method, define the layers the model will use.\n",
    "- In the call() method, define the forward pass of the model, reusing the layers previously created.\n",
    "- Instantiate your subclass, and call it on data to create its weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e68c8e-0469-4431-93fa-50874b40008b",
   "metadata": {},
   "source": [
    "###### A simple subclassed model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52732d2b-d6a3-477d-badf-7f57436dc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "    def __init__(self,num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation = \"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\",name=\"priority\")\n",
    "        self.department_classifier = layers.Dense(num_departments,activation = \"softmax\",name =\"department\")\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #Call function defines the forward pass for the model\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags_input = inputs[\"tags\"]\n",
    "        # Concatenate inputs and extract features from the mixing layer\n",
    "        features = self.concat_layer([title,text_body,tags_input])\n",
    "        features = self.mixing_layer(features)\n",
    "        # Get the outputs\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority,department\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f315a415-6c53-4de8-8443-2ffdfb952f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_model = CustomerTicketModel(num_departments=4)\n",
    "priority, department = subclass_model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7850f5c-bd2d-4161-990c-7fed5fd67a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'concatenate_1'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.layers[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "476825b5-97bc-4a64-88cc-92b75bb07928",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclass_model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[ \"mean_squared_error\",\"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79a70406-7e99-4c4b-ac34-f0d0eb5c00fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'customer_ticket_model/dense_7/kernel:0' shape=(20100, 64) dtype=float32, numpy=\n",
       " array([[-0.0158067 , -0.01025675,  0.00256464, ...,  0.00309089,\n",
       "          0.01057186,  0.00579896],\n",
       "        [ 0.01597054, -0.01224237, -0.01332647, ...,  0.00870516,\n",
       "         -0.00602563,  0.01266253],\n",
       "        [-0.01298345, -0.00670556, -0.01568459, ...,  0.01342695,\n",
       "         -0.01549362, -0.00273241],\n",
       "        ...,\n",
       "        [-0.01204981, -0.01336396, -0.00196782, ..., -0.01147019,\n",
       "         -0.00569996, -0.00258988],\n",
       "        [-0.01417327,  0.00237141, -0.00037594, ..., -0.01665332,\n",
       "          0.00068043,  0.01009944],\n",
       "        [ 0.00180505,  0.00479469, -0.01505111, ...,  0.01583019,\n",
       "         -0.0044933 , -0.0012497 ]], dtype=float32)>,\n",
       " <tf.Variable 'customer_ticket_model/dense_7/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.layers[1].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef6f34af-8e26-4e19-80ec-2310a0d40663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 1.5550 - output_1_loss: 0.1670 - output_2_loss: 1.3880 - output_1_mean_absolute_error: 0.4087 - output_2_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ac7c610>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.fit({\"title\": title_data, \"text_body\": text_body_data,\"tags\": tags_data},\n",
    "          [ priority_score, department_data],epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "719b0ccb-3798-49b2-a307-42e7b9df928e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 292ms/step - loss: 1.3292 - output_1_loss: 0.1705 - output_2_loss: 1.1587 - output_1_mean_absolute_error: 0.4129 - output_2_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3292113542556763,\n",
       " 0.1704850047826767,\n",
       " 1.1587263345718384,\n",
       " 0.41289830207824707,\n",
       " 1.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subclass_model.evaluate({\"title\": title_data, \"text_body\": text_body_data,\"tags\": tags_data}, \n",
    "                        [priority_score, department_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d75bbce6-3442-40c2-adbc-9aaa55a20ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n"
     ]
    }
   ],
   "source": [
    "priority_preds, department_preds = subclass_model.predict({\"title\": title_data, \"text_body\": text_body_data,\"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7497267-1175-474e-83d4-9a1e8b112a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48710167]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceb0109e-b7cc-4a76-9100-d9502cb6c857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31388572, 0.2303415 , 0.20782499, 0.24794778]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "department_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda71e9-e2bc-4ed1-9ec5-a0eeeae22f2a",
   "metadata": {},
   "source": [
    "#### Creating a Functional model that includes a subclassed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d826a5-7fb8-4ac1-812f-0a8d04245fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier_model(keras.Model):\n",
    "    def __init__(self,num_classes):\n",
    "        super().__init__()\n",
    "        if num_classes==2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self,inputs):\n",
    "        return self.dense(inputs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b94f73c5-35f6-4788-801d-764f5187bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64,activation=\"relu\")(inputs)\n",
    "outputs = Classifier_model(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff5ceab-2394-4d7c-a17a-03c6f6e682f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4613faf6-e7aa-478b-b9f2-5b828ef6fb54",
   "metadata": {},
   "source": [
    "#### Creating a subclassed model that includes a Functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1aa43267-2eea-48e4-befb-c2966f75a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (64,))\n",
    "outputs = layers.Dense(1, activation = \"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs = inputs,outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1aaddba0-74d0-4da9-b1a0-42ed74a279e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self,num_classes =2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64,activation =\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self,inputs):\n",
    "        features = self.dense(features)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ebe80-00a2-4b15-bbc8-b83f1646a089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55dfef57-ddd8-47ec-b5c7-6d94dff9d94e",
   "metadata": {},
   "source": [
    "#### The standard workflow: compile(), fit(), evaluate(), predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3267c428-7219-4af2-84e0-3860542f31d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnis_model():\n",
    "    inputs = keras.Input(shape = (28*28,))\n",
    "    features = layers.Dense(512,activation = \"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10,activation = \"softmax\")(features)\n",
    "    model = keras.Model(inputs = inputs, outputs = outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3a8cce8-4d86-40a9-974a-9be087dd454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data, reserving some for validation and scaling it\n",
    "(images,labels),(test_images,test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255 \n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255 \n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27fbea3f-48a6-4b37-b565-289140ec3072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2949 - accuracy: 0.9115 - val_loss: 0.1425 - val_accuracy: 0.9581\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1589 - accuracy: 0.9537 - val_loss: 0.1137 - val_accuracy: 0.9690\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1305 - accuracy: 0.9637 - val_loss: 0.1025 - val_accuracy: 0.9730\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9736\n",
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "model = get_mnis_model()\n",
    "#Compile the model by specifying its optimizer, the loss function to minimize, and the metrics to monitor.\n",
    "model.compile(optimizer = \"rmsprop\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics =[\"accuracy\"])\n",
    "#Use fit() to train the model, optionally providing validation data to monitor performance on unseen data\n",
    "model.fit(train_images, train_labels,epochs=3,validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels) # Use evaluate() to compute the loss and metrics on new data.\n",
    "predictions = model.predict(test_images) # Use predict() to compute classification probabilities on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f05a961a-d3c0-45f2-a915-3622059e86ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09369555115699768, 0.9735999703407288]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1f330-efbf-444f-a8c7-341566e6a396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd361ffa-86d9-4f35-8dd5-3bacc7ec6a38",
   "metadata": {},
   "source": [
    "#### Implementing a custom metric by subclassing the Metric class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e437b19-b669-41cc-b092-3fb10ea4d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "    def __init__(self,name=\"rmse\", **kwargs):\n",
    "        super().__init__(name= name,**kwargs)\n",
    "        #Define the state variables in the constructor. Like for layers, you have access to the add_weight() method.\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(name = \"total_samples\",initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "\n",
    "    def update_state(self,y_true, y_pred, sample_weight=None):\n",
    "        #To match our MNIST model, we expect categorical predictions and integer labels\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred)) ## compute mean square error for this state\n",
    "        self.mse_sum.assign_add(mse) # add it to the mse_sum\n",
    "        num_samples = tf.shape(y_pred)[0] # Get the number of samples in the batch \n",
    "        self.total_samples.assign_add(num_samples) # add it to total_samples variable\n",
    "\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum/tf.cast(self.total_samples,tf.float32))\n",
    "\n",
    "    # to reset the metric state without having to reinstantiate it\n",
    "    # this enables the same metric objects to be used across different epochs of training or across both training and evaluation\n",
    "    def reset_state(self): \n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7485a3d0-815e-4975-8ebd-46de0e79d838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.2940 - accuracy: 0.9127 - rmse: 7.1760 - val_loss: 0.1564 - val_accuracy: 0.9544 - val_rmse: 7.3505\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1622 - accuracy: 0.9535 - rmse: 7.3504 - val_loss: 0.1113 - val_accuracy: 0.9679 - val_rmse: 7.4028\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1301 - accuracy: 0.9630 - rmse: 7.3837 - val_loss: 0.1060 - val_accuracy: 0.9715 - val_rmse: 7.4200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9722 - rmse: 7.4318\n"
     ]
    }
   ],
   "source": [
    "model = get_mnis_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,epochs=3,validation_data=(val_images, val_labels)) \n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e18835-aeff-4a6d-8e01-3d2f0c7e63ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd1f256b-2977-42cf-91f3-aabd6ad0607c",
   "metadata": {},
   "source": [
    "### Using callbacks(THE EARLYSTOPPING AND MODELCHECKPOINT CALLBACKS):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c22cbb1-d226-4d98-a3d8-dc779c66a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # Interrupts training when improvement stops\n",
    "        monitor=\"val_accuracy\", # Monitors the model’s validation accuracy\n",
    "        patience=2,),# Interrupts training when accuracy has stopped improving for two complete epochs\n",
    "    keras.callbacks.ModelCheckpoint( # Saves the current weights after every epoch\n",
    "        filepath=\"checkpoint_path.keras\", # Path to the destination model file\n",
    "        monitor=\"val_loss\", # These two arguments mean you won’t overwrite the model file unless val_loss has improved,\n",
    "        save_best_only=True, # which allows you to keep the best model seen during training\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "52b92be5-bdac-4c71-945d-23aba8a120fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2944 - accuracy: 0.9115 - val_loss: 0.1495 - val_accuracy: 0.9556\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1601 - accuracy: 0.9537 - val_loss: 0.1175 - val_accuracy: 0.9677\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.1318 - accuracy: 0.9636 - val_loss: 0.1009 - val_accuracy: 0.9726\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.1139 - accuracy: 0.9679 - val_loss: 0.0921 - val_accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1012 - accuracy: 0.9726 - val_loss: 0.0969 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0954 - accuracy: 0.9729 - val_loss: 0.0986 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0901 - accuracy: 0.9757 - val_loss: 0.0935 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0835 - accuracy: 0.9775 - val_loss: 0.0872 - val_accuracy: 0.9792\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.0754 - accuracy: 0.9799 - val_loss: 0.0912 - val_accuracy: 0.9773\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0748 - accuracy: 0.9798 - val_loss: 0.0900 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b9ded90>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mnist = get_mnis_model()\n",
    "\n",
    "model_mnist.compile(optimizer = \"rmsprop\",\n",
    "             loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model_mnist.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels)) # Note that because the callback\n",
    "# will monitor validation loss and validation accuracy, you need to pass validation_data to the call to fit().\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "982794c6-046f-4ffd-8aa4-b810cbf499de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bdc8954-8e8f-4eca-91fe-93815cc8540d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x14e068a90>,\n",
       " <keras.layers.core.dense.Dense at 0x14db45c50>,\n",
       " <keras.layers.regularization.dropout.Dropout at 0x15e1a64d0>,\n",
       " <keras.layers.core.dense.Dense at 0x14d9b37d0>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1661ae49-b097-421d-9233-32a68ff86274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512,), dtype=float32, numpy=\n",
       "array([ 1.72143057e-02,  5.33041731e-02, -2.11188607e-02,  2.34439448e-02,\n",
       "       -2.48031951e-02,  5.72540015e-02,  3.67634669e-02,  1.83934942e-02,\n",
       "        5.95329255e-02,  1.12114474e-02, -4.58365344e-02,  6.15462512e-02,\n",
       "       -5.45365214e-02,  6.10567778e-02,  5.42108268e-02, -2.91005895e-02,\n",
       "        3.66051346e-02, -5.37955984e-02, -3.27389836e-02,  3.31528932e-02,\n",
       "       -5.84965721e-02, -4.45696041e-02,  3.44118774e-02, -3.30656506e-02,\n",
       "       -9.57584754e-03,  5.10456413e-02,  2.79021785e-02, -5.28070740e-02,\n",
       "       -5.20403758e-02,  4.34310734e-03, -1.19869225e-02,  1.55859441e-02,\n",
       "        5.32143041e-02, -2.90853418e-02, -5.81286810e-02, -6.14078455e-02,\n",
       "        2.31676623e-02, -4.06935513e-02,  1.49313733e-02,  6.02196902e-03,\n",
       "       -1.71985589e-02,  3.32952589e-02, -6.08684868e-02,  5.46014234e-02,\n",
       "       -1.96977705e-02, -5.41275740e-02, -5.75990714e-02,  1.35181472e-02,\n",
       "       -3.02809738e-02, -4.36169468e-02, -1.18226707e-02,  2.27023214e-02,\n",
       "        2.59374753e-02, -3.63529101e-02, -3.62856202e-02, -3.88381556e-02,\n",
       "       -2.26134732e-02, -6.69121146e-02, -2.95587555e-02,  3.05586979e-02,\n",
       "        3.50711197e-02,  5.08503243e-02,  1.17329434e-02,  5.37394211e-02,\n",
       "        3.88165638e-02,  1.09859258e-02,  5.27894869e-02, -1.00310780e-02,\n",
       "        4.25536186e-02, -1.46513917e-02,  3.73369083e-02,  3.63393947e-02,\n",
       "        2.92645022e-02, -3.93687710e-02,  4.12170812e-02,  6.69158250e-02,\n",
       "        1.10764131e-02, -5.72196767e-02, -2.23259665e-02, -5.16724363e-02,\n",
       "        1.57434493e-02,  4.72842157e-03,  1.15477070e-02, -1.28066540e-02,\n",
       "        4.19534892e-02,  4.12650481e-02,  1.77751482e-02, -2.81639770e-02,\n",
       "        4.36104834e-04,  5.77027202e-02, -2.62143463e-02,  5.77495545e-02,\n",
       "        5.27484342e-02,  3.87615561e-02, -3.62940244e-02, -5.38353920e-02,\n",
       "        4.31165993e-02, -1.48658045e-02, -4.48325649e-02, -4.99603972e-02,\n",
       "       -6.41068220e-02,  5.92256039e-02,  4.29434776e-02,  5.97537309e-02,\n",
       "       -3.86768095e-02, -2.03402713e-02, -2.48876996e-02, -3.82154435e-03,\n",
       "       -7.24115968e-03,  4.88252863e-02, -4.62970883e-02, -1.15018599e-02,\n",
       "        3.23966146e-03, -2.07222104e-02, -4.30841558e-02,  3.02569792e-02,\n",
       "        1.03982389e-02,  2.54635736e-02, -3.27514745e-02, -3.23324651e-02,\n",
       "        6.12878352e-02, -5.01367822e-02, -4.48211618e-02,  6.25757724e-02,\n",
       "       -5.92289753e-02,  1.32169798e-02,  5.36160916e-03, -3.51405852e-02,\n",
       "       -1.41862966e-02, -3.92241180e-02,  2.60303020e-02,  4.72329557e-04,\n",
       "        2.03012228e-02,  4.83768731e-02, -5.17722368e-02,  2.75729150e-02,\n",
       "        2.52368823e-02, -6.77226782e-02, -3.56102362e-02, -2.64432915e-02,\n",
       "       -1.13943219e-02,  2.60906368e-02, -4.09803800e-02,  4.57914397e-02,\n",
       "        1.64204985e-02, -3.63131016e-02, -3.89717445e-02, -4.80591208e-02,\n",
       "       -4.30553481e-02,  4.18201312e-02,  2.40475759e-02,  4.66485620e-02,\n",
       "        3.57275233e-02, -1.92732625e-02,  4.04129401e-02,  3.75248119e-02,\n",
       "        2.26736069e-03, -4.19558771e-02, -1.71555504e-02, -2.05973461e-02,\n",
       "        2.17681304e-02, -3.65705192e-02, -1.65502802e-02,  4.81224060e-02,\n",
       "        1.65251046e-02,  6.31904900e-02, -6.75229058e-02,  1.78950503e-02,\n",
       "        5.67761734e-02, -1.46085657e-02,  5.41169494e-02, -2.75637843e-02,\n",
       "       -4.60051000e-02, -2.30000354e-02, -4.06132527e-02,  1.84259862e-02,\n",
       "        4.99309376e-02,  3.34955603e-02, -1.09719075e-02,  3.14229727e-03,\n",
       "       -1.29556879e-02, -3.07475291e-02, -2.86366791e-02,  3.86480987e-03,\n",
       "        6.59524798e-02, -5.78310341e-02, -5.53375632e-02, -3.30676772e-02,\n",
       "       -3.26530673e-02, -2.94123515e-02, -3.51126157e-02, -1.03641227e-02,\n",
       "        2.99851596e-03,  3.84646505e-02, -5.80016263e-02, -4.23556603e-02,\n",
       "       -5.44975549e-02,  2.16604099e-02,  7.55234063e-03, -6.65557459e-02,\n",
       "       -2.33003609e-02,  3.19567919e-02,  5.64338192e-02,  2.93791890e-02,\n",
       "       -2.79508159e-02, -2.00121105e-02,  5.22556752e-02,  4.95460778e-02,\n",
       "       -4.13076803e-02, -2.35038847e-02,  4.69817370e-02,  4.01941314e-02,\n",
       "        6.47598058e-02, -1.35758519e-03, -5.12831807e-02,  1.28023028e-02,\n",
       "       -9.84974578e-03,  3.07855234e-02, -2.20842026e-02,  4.35696393e-02,\n",
       "        4.65743095e-02,  4.32910770e-03, -2.34340951e-02,  6.17400706e-02,\n",
       "       -3.60359922e-02,  5.43680489e-02, -4.98148017e-02,  4.20831218e-02,\n",
       "        2.26019323e-03,  3.06784883e-02, -2.88214199e-02, -5.16812429e-02,\n",
       "       -5.92656732e-02, -4.98406924e-02,  3.98090333e-02, -2.55951062e-02,\n",
       "        4.25244570e-02,  6.48789108e-02,  6.71584606e-02,  6.19421005e-02,\n",
       "        3.89345735e-03,  3.34037766e-02,  6.60010576e-02,  5.66519126e-02,\n",
       "       -2.97158845e-02, -2.79206075e-02,  1.39323846e-02, -2.50710584e-02,\n",
       "        1.71297267e-02,  5.30009791e-02, -4.74069379e-02, -6.64736405e-02,\n",
       "       -3.97712328e-02,  4.40043211e-02,  3.84616032e-02,  3.85729373e-02,\n",
       "       -1.07380636e-02, -1.95364207e-02, -2.48998664e-02,  5.21526635e-02,\n",
       "       -6.56740740e-02,  2.72166729e-02,  5.95538765e-02,  6.24171495e-02,\n",
       "       -2.72746198e-02,  1.87724307e-02, -3.15809846e-02,  3.61114591e-02,\n",
       "       -4.48777527e-03, -5.16911596e-03, -1.49154589e-02,  2.63511166e-02,\n",
       "       -4.81147021e-02,  5.09276241e-02,  3.94508913e-02,  5.73290586e-02,\n",
       "        3.26450244e-02, -5.12563661e-02, -4.88777980e-02,  2.85840407e-02,\n",
       "       -1.53567381e-02,  6.20611906e-02,  5.75912893e-02,  4.53580767e-02,\n",
       "        1.88761577e-02, -4.50479016e-02, -2.22134814e-02, -5.88681921e-02,\n",
       "       -4.96096909e-04,  6.79660589e-02, -2.70490162e-02,  5.75698763e-02,\n",
       "       -4.11688164e-02,  5.66305816e-02,  2.73605362e-02, -5.22438437e-03,\n",
       "       -3.72423008e-02, -1.05634443e-02,  1.14262775e-02,  2.80550271e-02,\n",
       "        1.91558152e-03,  4.16461155e-02, -3.15390825e-02,  1.43859759e-02,\n",
       "       -2.82482207e-02,  6.19864464e-02,  2.53799781e-02,  6.31540120e-02,\n",
       "       -3.84679288e-02,  3.43754888e-04, -5.01795933e-02, -3.28905620e-02,\n",
       "        5.48865348e-02,  1.22107714e-02, -3.78204510e-02,  1.10545903e-02,\n",
       "        7.64780492e-03,  6.00339472e-02, -2.70899609e-02,  1.08724684e-02,\n",
       "        2.70799547e-02, -2.39394717e-02, -2.56714970e-02, -5.82593679e-02,\n",
       "        4.59329113e-02, -4.58498299e-03,  2.67653987e-02, -1.72543302e-02,\n",
       "        4.79164496e-02, -5.11603281e-02,  5.18514812e-02,  5.35026416e-02,\n",
       "        6.52963966e-02, -5.69971725e-02, -1.06839463e-02, -1.78262480e-02,\n",
       "        4.09885719e-02,  2.28196904e-02,  4.54233810e-02, -5.84524795e-02,\n",
       "        6.00977242e-03, -3.79168391e-02,  4.64259908e-02,  2.99532488e-02,\n",
       "        3.13369185e-02,  1.19550973e-02, -6.28218949e-02,  6.37542754e-02,\n",
       "       -1.69977732e-02,  6.68697059e-04, -2.72765979e-02, -5.39352559e-02,\n",
       "       -2.10658312e-02,  1.64792612e-02, -5.84926605e-02, -5.92731014e-02,\n",
       "       -4.75434959e-02,  3.49888429e-02, -5.48133887e-02,  5.17964065e-02,\n",
       "        3.41176987e-02,  4.16488200e-02,  1.53513551e-02, -1.78758800e-03,\n",
       "        6.67690635e-02, -6.59681857e-04, -4.10390720e-02, -6.52721003e-02,\n",
       "        9.00686532e-03,  5.06209210e-02,  3.52401733e-02, -4.04320508e-02,\n",
       "       -5.02071232e-02, -2.66051292e-03,  6.63403720e-02, -3.14571261e-02,\n",
       "        4.67739776e-02,  3.94726470e-02, -6.07269630e-02, -1.66615024e-02,\n",
       "       -1.98310539e-02, -1.71269849e-02,  1.01227984e-02, -2.07557566e-02,\n",
       "        5.08098155e-02,  8.58451426e-03, -2.82540917e-03, -2.94922926e-02,\n",
       "        5.70679903e-02, -5.75636886e-02,  2.76750326e-02,  2.95813382e-02,\n",
       "       -6.69144019e-02, -1.73952058e-02,  1.66669190e-02, -5.72189800e-02,\n",
       "        3.29940170e-02,  7.64004886e-03,  3.42304632e-02, -5.98205887e-02,\n",
       "       -1.53189264e-02,  3.40067446e-02, -4.35048193e-02,  5.31036034e-02,\n",
       "        1.38469264e-02,  2.38728002e-02,  5.59989959e-02,  3.03243995e-02,\n",
       "        2.56738812e-02,  5.96217364e-02,  1.96903720e-02, -1.57447755e-02,\n",
       "        6.43301755e-02, -2.27110200e-02, -2.32308954e-02, -4.16955724e-02,\n",
       "       -6.14733510e-02, -1.35682113e-02,  2.41432562e-02, -2.59387270e-02,\n",
       "       -1.25847012e-02,  1.56504437e-02, -2.13643536e-02,  3.27107906e-02,\n",
       "        1.59746930e-02,  3.64037007e-02,  4.93423119e-02, -2.69225314e-02,\n",
       "       -2.10727900e-02,  5.25152832e-02,  4.86968532e-02, -4.18355092e-02,\n",
       "       -6.12856597e-02, -4.50628996e-03,  4.49825600e-02,  2.51690894e-02,\n",
       "       -2.46730931e-02, -3.20507325e-02,  3.12336832e-02,  6.71168566e-02,\n",
       "        4.61267829e-02,  2.45886892e-02,  2.88344771e-02,  5.43589219e-02,\n",
       "       -6.25383481e-02,  3.14109549e-02, -1.85313858e-02,  1.32942498e-02,\n",
       "        6.02056235e-02, -5.99006936e-02,  3.08847204e-02, -2.32825167e-02,\n",
       "        2.45441273e-02, -2.28778981e-02, -3.51990350e-02, -1.94758475e-02,\n",
       "       -1.28940269e-02,  5.69909811e-04,  3.88076752e-02,  5.05059361e-02,\n",
       "       -9.86836851e-04,  2.57695615e-02,  4.33643907e-03, -5.61045557e-02,\n",
       "        1.70782879e-02,  5.28268963e-02,  3.25640067e-02, -5.90695590e-02,\n",
       "        2.57641077e-05,  4.35710177e-02, -2.87746824e-02,  6.34804964e-02,\n",
       "        7.96510279e-03,  8.45785439e-03, -6.63931966e-02,  2.71602497e-02,\n",
       "        1.18859410e-02,  1.12801492e-02, -1.92167759e-02, -5.71340248e-02,\n",
       "        3.82233784e-02,  1.94109902e-02,  3.14493552e-02, -1.22678950e-02,\n",
       "       -4.74941134e-02, -4.62881178e-02,  1.08948350e-02, -5.64039573e-02,\n",
       "       -1.89206861e-02, -5.42897657e-02,  9.50676948e-03, -6.73175454e-02,\n",
       "        1.88569352e-02,  4.37099785e-02, -4.52144407e-02,  5.37458435e-02,\n",
       "       -6.76847696e-02, -4.89684194e-02, -3.61389555e-02, -4.02311981e-02,\n",
       "       -5.89013658e-02, -4.54723611e-02, -4.96754050e-03,  7.32421875e-03,\n",
       "       -5.00557572e-03, -2.89283730e-02, -4.54253145e-02,  8.08148086e-03,\n",
       "        5.79860955e-02,  6.33654594e-02, -6.33111969e-03, -3.76779512e-02],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint.weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba41b67-3ee0-4763-8842-ea88a3b056b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dabc21e-d8d9-4358-96c8-aa0b2e084b45",
   "metadata": {},
   "source": [
    "#### Creating a custom callback by subclassing the Callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3d3ef5af-73ad-4fd8-a020-5288dee7d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses, label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"losses_epochs/plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8a03ed7-34ec-48ae-82d4-7112d548911a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.2921 - accuracy: 0.9123 - val_loss: 0.1470 - val_accuracy: 0.9588\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1604 - accuracy: 0.9533 - val_loss: 0.1185 - val_accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1318 - accuracy: 0.9643 - val_loss: 0.1040 - val_accuracy: 0.9725\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1144 - accuracy: 0.9686 - val_loss: 0.0976 - val_accuracy: 0.9733\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1044 - accuracy: 0.9714 - val_loss: 0.0968 - val_accuracy: 0.9754\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0957 - accuracy: 0.9744 - val_loss: 0.0926 - val_accuracy: 0.9771\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0883 - accuracy: 0.9765 - val_loss: 0.0908 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0817 - accuracy: 0.9775 - val_loss: 0.0919 - val_accuracy: 0.9790\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0771 - accuracy: 0.9787 - val_loss: 0.0927 - val_accuracy: 0.9796\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0741 - accuracy: 0.9803 - val_loss: 0.0903 - val_accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160e62ed0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnis_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eb8b7f-3cb7-4499-b6d2-dbe6d6516146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "012e69d1-f912-4a5b-aad4-f4187c24e037",
   "metadata": {},
   "source": [
    "#### Monitoring and visualization with TensorBoard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f288766-5599-427e-a317-94c0ba8b0357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2946 - accuracy: 0.9116 - val_loss: 0.1543 - val_accuracy: 0.9549\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1619 - accuracy: 0.9539 - val_loss: 0.1256 - val_accuracy: 0.9650\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1302 - accuracy: 0.9634 - val_loss: 0.0991 - val_accuracy: 0.9727\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 0.1138 - accuracy: 0.9682 - val_loss: 0.0861 - val_accuracy: 0.9759\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1048 - accuracy: 0.9707 - val_loss: 0.0949 - val_accuracy: 0.9761\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0956 - accuracy: 0.9749 - val_loss: 0.0943 - val_accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0877 - accuracy: 0.9766 - val_loss: 0.0911 - val_accuracy: 0.9773\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.0804 - accuracy: 0.9786 - val_loss: 0.0957 - val_accuracy: 0.9774\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0738 - accuracy: 0.9800 - val_loss: 0.0890 - val_accuracy: 0.9796\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.0740 - accuracy: 0.9797 - val_loss: 0.0957 - val_accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16273e1d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnis_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/Users/macbookpro/Desktop/Study/Deep_Learning/Deep_Learning_Keras/Tensor_board\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2990f2c-49c9-4687-ab45-6cf7d1f7671f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c965e12-3087-4ae9-9bca-a45a55cfcd0e",
   "metadata": {},
   "source": [
    "### Custom Train Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c637fc2-168a-4672-95a6-271a38ed9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape: # TensorFlow provides the tf.GradientTape API for automatic differentiation; \n",
    "        #that is, computing the gradient of computation for some inputs, \n",
    "        #usually tf.Variables. \n",
    "        #TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". \n",
    "        #TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
    "        predictions = model(inputs,training=True) # First pass the inputs to the model to perform the forward pass\n",
    "        loss = loss_fn(targets, predictions) # Then, compute the loss function between the predictions and targets\n",
    "        gradients = tape.gradient(loss, model.trainable_weights) # After compute gradients of trainable weights\n",
    "        optimizer.apply_gradients(zip(model.trainable_weights, gradients)) # Update the model’s weights\n",
    "                                                                           #to lower the loss value on the current batch of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4586b9-6840-4dd1-8ac7-559d368c4f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84e61369-c0aa-47c0-bd70-cebb0ec3b7f3",
   "metadata": {},
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fe07cdbb-3b2a-44b6-b41e-b3e1d9069759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]] \n",
    "metric.update_state(targets, predictions) \n",
    "current_result = metric.result() \n",
    "print(f\"result: {current_result:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3daeb661-253c-4d66-8577-d3b555addd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4] \n",
    "mean_tracker = keras.metrics.Mean() \n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ebc9a4-610c-45d2-8120-8c4d70cae780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "073461f1-c55d-49d7-9985-bdb471146655",
   "metadata": {},
   "source": [
    "### Combine them and create full training loop and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ce9449e2-2ad7-4452-885a-616fc47a5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mnis_model()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy() # Prepare the loss function.\n",
    "optimizer = keras.optimizers.RMSprop() # Prepare the optimizer.\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()] # Prepare the list of metrics to monitor.\n",
    "loss_tracking_metric = keras.metrics.Mean() # Prepare a Mean metric tracker to keep track of the loss average\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    targets = targets.numpy()\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs,training=True) # Run the forward pass. Note that we pass training=True.\n",
    "        loss = loss_fn(targets, predictions) \n",
    "    gradients = tape.gradient(loss, model.trainable_weights) #Run the backward pass. Note that we use model.trainable_weights.\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions) \n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# resetting the metrics\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "20e2e6e9-b756-4b1f-94ea-47271e044537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 23:05:13.316574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [50000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9141\n",
      "...loss: 0.2910\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9540\n",
      "...loss: 0.1586\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9640\n",
      "...loss: 0.1305\n"
     ]
    }
   ],
   "source": [
    "# Writing a step-by-step training loop: the loop itself\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32) \n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch) \n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a130e3c3-eee0-46e7-aed6-ffb93a218b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "189215c2-0eb5-41b8-8862-0270cd6a1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing a step-by-step evaluation loop\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False) \n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result() \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d665d5f-ee41-4917-a1b1-e8ea1e017a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eb1b4884-b25f-40f6-9fb8-317bd7e949bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 23:25:51.204055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [10000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9676\n",
      "...val_loss: 0.1250\n",
      "Seconds since start = 3.8605949878692627\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32) \n",
    "epochs = 3\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch) \n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")\n",
    "    \n",
    "end_time = time.time()\n",
    "print(\"Seconds since start =\", end_time-start_time)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3d32b239-cc70-4d92-a1bb-bdd6fd1b234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make it fast with tf.function\n",
    "\n",
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False) \n",
    "    loss = loss_fn(targets, predictions)\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result() \n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "98c0e8db-0472-4c1f-ba97-7cc645851154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 23:26:12.101493: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype uint8 and shape [10000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9676\n",
      "...val_loss: 0.1250\n",
      "Seconds since start = 1.335447072982788\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32) \n",
    "epochs = 3\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch) \n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Seconds since start =\", end_time-start_time)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc0f58-53b6-41a0-9c80-c47fe9d6b887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3747811b-812d-4edb-95e3-54fe658a6f0c",
   "metadata": {},
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "45c12a2b-910f-4627-86d0-c3246f8f9054",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5e3750e0-95e3-4616-9582-3831c8979a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2936\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.1591\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1666ffc90>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6f214c56-095c-4cd1-8b95-6d900ed51295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions) # Update the model’s metrics via self.compiled_metrics.\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee335aa7-2bdc-4728-875c-ccc7929a2f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 14s 8ms/step - loss: 0.2961 - sparse_categorical_accuracy: 0.9116\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.1283 - sparse_categorical_accuracy: 0.9636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x168930f90>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b50c2e-d2f3-41ce-9bb0-5d1e618c44d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
